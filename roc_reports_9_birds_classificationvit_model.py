# -*- coding: utf-8 -*-
"""ROC reports-9 birds classificationvit_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CSgiDn8CNX_iqbAH5sC8aBeqqAxku9K1

# Connect Gdrive

---
"""

# unzip images and reate image folders on drive
!cd /content
!unzip /content/drive/MyDrive/datasets/birds/cropped_petrel.zip
# Define paths
DATASET_PATH ="/content/cropped_petrel/"

# Commented out IPython magic to ensure Python compatibility.
# %%time
# import glob
# dataset_images = glob.glob(f"{DATASET_PATH}**/*.jpg")
# # Get dataset size
# total = len(dataset_images)
# 
# # View samples counts
# print(f'TOTAL: {total}')

"""# Load Libarary

---



---


"""

# System libraries
from pathlib import Path
import os.path
import random
import time
import glob
import copy
import time
import tensorflow.keras.callbacks as cb
import json

# Utilities
import pandas as pd, numpy as np
import seaborn as sns

# Sklearn
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,confusion_matrix
from sklearn.metrics import roc_curve, precision_recall_curve, auc
from sklearn.metrics import precision_recall_curve,average_precision_score,roc_auc_score, accuracy_score
from sklearn.preprocessing import label_binarize, LabelBinarizer
from sklearn.utils import class_weight
from sklearn.preprocessing import LabelEncoder
import matplotlib.colors as mcolors
from itertools import cycle
from matplotlib.axes import Axes
import mpl_toolkits.axes_grid1.inset_locator as mpl_il
from matplotlib.ticker import FormatStrFormatter

# Tensorflow Libraries
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Model
from tensorflow.keras import layers,models,Sequential
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Dense, Dropout, BatchNormalization, Flatten, GlobalAveragePooling2D, GlobalMaxPooling2D
from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import Model
from tensorflow.keras.layers.experimental import preprocessing
from tensorflow.keras import regularizers
import tensorflow_hub as hub
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.efficientnet import preprocess_input

# Visualization Libraries
import matplotlib.cm as cm
import cv2
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import interp

!wget https://raw.githubusercontent.com/LucaZheng/DLFunction/main/modifiedhelpers.py
from modifiedhelpers import generate_labels, build_df, _load, encode_labels, create_pipeline, train_model

"""## Add-in function block"""

# Concat pretrained + fc
def create_model(pretrained_model, model_name):
    initializer = tf.keras.initializers.GlorotNormal(seed=CFG.SEED)

    model_sequential = Sequential([
        layers.Input(shape=CFG.IMAGE_SIZE, dtype=tf.float32, name='input_image'),
        pretrained_model,
        layers.Dropout(0.2),
        layers.Dense(512, activation='relu', kernel_initializer=initializer),
        layers.Dense(256, activation='relu', kernel_initializer=initializer),
        layers.Dense(9, dtype=tf.float32, activation='softmax', kernel_initializer=initializer)
    ], name=model_name)

    return model_sequential

def compile_model(model):
    # Compile the model
    model.compile(
        loss=tf.keras.losses.CategoricalCrossentropy(),
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
        metrics=METRICS
    )

def train_model(model, epochs, callbacks, train_ds, val_ds):
    # Train the model
    print(f'Training {model.name}.')
    print(f'Train on {len(train_df)} samples, validate on {len(val_df)} samples.')
    print('----------------------------------')

    history = model.fit(
        train_ds,
        epochs=epochs,
        callbacks=callbacks,
        validation_data=val_ds
    )

    return history

import numpy as np
import matplotlib.pyplot as plt

# plotting function
# create a list of colors without red ones
color = ['tab:blue', 'tab:green', 'tab:purple', 'tab:brown']
# Assuming histories is a list of History objects and model_names is a list of the corresponding model names
def plot_history(histories, model_names, metric='val_loss', highlight=None):
    plt.figure(figsize=(10,6))

    for i, (history, model_name) in enumerate(zip(histories, model_names)):
        # get only the validation loss
        # change from history.history[metric] to down blow
        metric_values = history.history[metric]

        if model_name == highlight:
            # Highlight this model with thicker, dashed red line
            plt.plot(metric_values, 'r--', linewidth=2.5, label=model_name)
        else:
            # use colors from the colors list
            plt.plot(metric_values, color=color[i % len(color)], label=model_name)

    plt.xlabel('Epochs')
    plt.ylabel(metric)
    plt.title(f'{metric.capitalize()} vs. Epochs for No. Unfreezed Layers')
    plt.legend()
    plt.grid(True)
    plt.show()

def float32_and_ndarray_to_float(data):
    if isinstance(data, dict):
        return {k: float32_and_ndarray_to_float(v) for k, v in data.items()}
    elif isinstance(data, list):
        return [float32_and_ndarray_to_float(v) for v in data]
    elif isinstance(data, np.float32):
        return float(data)
    elif isinstance(data, np.ndarray):
        return data.tolist()
    else:
        return data

"""## Poltting tools

# One-hot lables and create DF
"""

class CFG:
    EPOCHS = 30
    BATCH_SIZES = 50
    SEED = 42
    TF_SEED = 768
    HEIGHT = 224
    WIDTH = 224
    CHANNELS = 3
    IMAGE_SIZE = (224, 224, 3)

# Build the Dataset DataFrame
dataset_df = build_df(dataset_images, generate_labels(dataset_images), seed=CFG.SEED)

# Label encoder
# Generate Label Encoder
label_encoder = LabelEncoder()

# Label Encode the Image Labels
dataset_df['label_encoded'] = label_encoder.fit_transform(dataset_df.label)

# View first 10 samples
dataset_df.head(50)

"""# Train test split"""

# Create Train/Test split with Training Set
train_split_idx, val_test_split_idx, _, _ = train_test_split(dataset_df.index,
                                                        dataset_df.label_encoded,
                                                        test_size=0.3,
                                                        stratify=dataset_df.label_encoded,
                                                        random_state=CFG.SEED)

# Get training and validation data
train_df = dataset_df.iloc[train_split_idx].reset_index(drop=True)
val_test_df = dataset_df.iloc[val_test_split_idx].reset_index(drop=True)

# Create Train/Test split with Training Set
val_split_idx, test_split_idx, _, _ = train_test_split(val_test_df.index,
                                                       val_test_df.label_encoded,
                                                       test_size=0.6,
                                                       stratify=val_test_df.label_encoded,
                                                       random_state=CFG.SEED)

# Get validation and test data
val_df = dataset_df.iloc[val_split_idx].reset_index(drop=True)
test_df = dataset_df.iloc[test_split_idx].reset_index(drop=True)
#test_df = dataset_df.iloc[test_split_idx]

"""# Augmentation"""

# Build augmentation layer
augmentation_layer = Sequential([
    layers.RandomFlip(mode='horizontal_and_vertical', seed=CFG.TF_SEED),
    layers.RandomZoom(height_factor=(-0.1, 0.1), width_factor=(-0.1, 0.1), seed=CFG.TF_SEED),
], name='augmentation_layer')

"""# Define Training strategies"""

# Define Early Stopping Callback
early_stopping_callback = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True)

# Define Reduce Learning Rate Callback
reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    patience=2,
    factor=0.1,
    verbose=1)

# Define Callbacks and Metrics lists
CALLBACKS = [early_stopping_callback, reduce_lr_callback]
METRICS = ['accuracy']
tf.random.set_seed(CFG.SEED)

"""# Pre-processing inputs ds generation"""

eff_preprocess = tf.keras.applications.efficientnet.preprocess_input
dense_preprocess = tf.keras.applications.densenet.preprocess_input

# Generate Train Input Pipeline
eff_train_ds = create_pipeline(train_df, _load, preprocess_function=eff_preprocess,
                           height=CFG.HEIGHT, width=CFG.WIDTH,
                           augment_layer=augmentation_layer,
                           augment=True,
                           batch_size=CFG.BATCH_SIZES,
                           if_vt = False,
                           shuffle=False, prefetch=True)

# Generate Validation Input Pipeline
eff_val_ds = create_pipeline(val_df, _load, preprocess_function=eff_preprocess,
                         height=CFG.HEIGHT, width=CFG.WIDTH,
                         augment_layer=None,
                         augment=False,
                         if_vt = False,
                         batch_size=CFG.BATCH_SIZES,
                         shuffle=False, prefetch=False)

# Generate Test Input Pipeline
eff_test_ds = create_pipeline(test_df, _load, preprocess_function=eff_preprocess,
                          height=CFG.HEIGHT, width=CFG.WIDTH,
                          augment_layer=None,
                          augment=False,
                          if_vt = False,
                          batch_size=CFG.BATCH_SIZES,
                          shuffle=False, prefetch=False)

# Generate Train Input Pipeline
dense_train_ds = create_pipeline(train_df, _load, preprocess_function=dense_preprocess,
                           height=CFG.HEIGHT, width=CFG.WIDTH,
                           augment_layer=augmentation_layer,
                           augment=True,
                           batch_size=CFG.BATCH_SIZES,
                           if_vt = False,
                           shuffle=False, prefetch=True)

# Generate Validation Input Pipeline
dense_val_ds = create_pipeline(val_df, _load, preprocess_function=dense_preprocess,
                         height=CFG.HEIGHT, width=CFG.WIDTH,
                         augment_layer=None,
                         augment=False,
                         if_vt = False,
                         batch_size=CFG.BATCH_SIZES,
                         shuffle=False, prefetch=False)

# Generate Test Input Pipeline
dense_test_ds = create_pipeline(test_df, _load, preprocess_function=dense_preprocess,
                          height=CFG.HEIGHT, width=CFG.WIDTH,
                          augment_layer=None,
                          augment=False,
                          if_vt = False,
                          batch_size=CFG.BATCH_SIZES,
                          shuffle=False, prefetch=False)

# Generate Train Input Pipeline
vit_train_ds = create_pipeline(train_df, _load, preprocess_function=None,
                           height=CFG.HEIGHT, width=CFG.WIDTH,
                           augment_layer=augmentation_layer,
                           augment=True,
                           batch_size=CFG.BATCH_SIZES,
                           if_vt = True,
                           shuffle=False, prefetch=True)

# Generate Validation Input Pipeline
vit_val_ds = create_pipeline(val_df, _load, preprocess_function=None,
                         height=CFG.HEIGHT, width=CFG.WIDTH,
                         augment_layer=None,
                         augment=False,
                         if_vt = True,
                         batch_size=CFG.BATCH_SIZES,
                         shuffle=False, prefetch=False)

# Generate Test Input Pipeline
vit_test_ds = create_pipeline(test_df, _load, preprocess_function=None,
                          height=CFG.HEIGHT, width=CFG.WIDTH,
                          augment_layer=None,
                          augment=False,
                          if_vt = True,
                          batch_size=CFG.BATCH_SIZES,
                          shuffle=False, prefetch=False)

"""# Define pre-trained models"""

!pip install -q vit-keras
!pip install tensorflow_addons

from vit_keras import vit

# efficientnet_pretrained model
eff_pretrained_model = tf.keras.applications.EfficientNetV2B2(
input_shape=(224, 224, 3),
include_top=False,
weights='imagenet',
pooling='max'
)

for layer in eff_pretrained_model.layers:
    layer.trainable = False

# densenet_pretrained model
dense_pretrained_model = tf.keras.applications.DenseNet201(
input_shape=(224, 224, 3),
include_top=False,
weights='imagenet',
pooling='max'
)

for layer in dense_pretrained_model.layers:
    layer.trainable = False

# vision transformer model
vit_pretrained_model = vit.vit_b16(
image_size=224,
activation='softmax',
pretrained=True,
include_top=False,
pretrained_top=False,
classes=9)

for layer in vit_pretrained_model.layers:
    layer.trainable = True

"""# Create models and define trainable layers"""

eff_blocks_to_unfreeze = ['top_', 'block6']
dense_blocks_to_unfreeze = ['conv5_']

# setting trainable layers
for layer in eff_pretrained_model.layers:  # Iterate over layers, not the model
    if any(block in layer.name for block in eff_blocks_to_unfreeze) and 'bn' not in layer.name:
      layer.trainable = True

for layer in dense_pretrained_model.layers:  # Iterate over layers, not the model
    if any(block in layer.name for block in dense_blocks_to_unfreeze) and 'bn' not in layer.name:
      layer.trainable = True

# Generate concated Model (pretrain+fc)
eff_model = create_model(eff_pretrained_model,model_name='EfficientNetV2B2')
dense_model = create_model(dense_pretrained_model,model_name='DenseNet201')
vit_model = create_model(vit_pretrained_model,model_name='ViT')

# Complie for training
compile_model(eff_model)
compile_model(dense_model)
compile_model(vit_model)

# Check if desired layers were unfrozen
def print_layer_info(model, prefix=""):
    for i, layer in enumerate(model.layers):
        print(prefix + str(i), layer.name, layer.trainable)
        if isinstance(layer, tf.keras.Model):
            print_layer_info(layer, prefix + str(i) + "_")

print_layer_info(vit_model)

"""# Train all models"""

def train_model(model, epochs, callbacks, train_ds, val_ds):
  # Train the model
  print(f'Training {model.name}.')
  print(f'Train on {len(train_df)} samples, validate on {len(val_df)} samples.')
  print('----------------------------------')
  start_time = time.time()

  history = model.fit(
        train_ds,
        epochs=epochs,
        callbacks=callbacks,
        validation_data=val_ds
  )
  end_time = time.time()
  training_time = end_time - start_time

  return history, training_time

all_histories = []
all_training_times = []

eff_history, eff_training_time = train_model(eff_model, 100, CALLBACKS, eff_train_ds, eff_val_ds)
dense_history, dense_training_time = train_model(dense_model, 100, CALLBACKS, dense_train_ds, dense_val_ds)
vit_history, vit_training_time = train_model(vit_model, 100, CALLBACKS, vit_train_ds, vit_val_ds)

# append all histories and times into list
all_histories.append(eff_history)
all_histories.append(dense_history)
all_histories.append(vit_history)

all_training_times.append(eff_training_time)
all_training_times.append(dense_training_time)
all_training_times.append(vit_training_time)

all_training_times

# loss visualization
plot_history(all_histories, ['EfficientNetB2V2', 'DenseNet201', 'ViT'], 'val_loss', highlight=None)

# validation visualization
plot_history(all_histories, ['EfficientNetB2V2', 'DenseNet201', 'ViT'], 'val_accuracy', highlight=None)

"""## Generate ROC graphs"""

# Separate labels from dense_test_ds
y_true = np.concatenate([y for x, y in dense_test_ds], axis=0)
y_true = np.argmax(y_true, axis=-1)

# Predictions
eff_preds = eff_model.predict(eff_test_ds)
dense_preds = dense_model.predict(dense_test_ds)
vit_preds = vit_model.predict(vit_test_ds)

preds = [eff_preds,dense_preds,vit_preds]
y_preds = []

for pred in preds:
    # Get predicted classes from probabilities
    pred = np.argmax(pred, axis=1)
    y_preds.append(pred)

all_accs = []
for pred in y_preds:
    # Calculate accuracy
    accuracy = accuracy_score(y_true, pred)

    # Append
    all_accs.append(accuracy)

all_accs

from sklearn.metrics import confusion_matrix
import seaborn as sns

class_names = list(label_encoder.classes_)
model_preds = {
    'EfficientNetV2B2': y_preds[0],
    'DenseNet201': y_preds[1],
    'ViT': y_preds[2]
}

def plot_multiclass_confusion_matrix(y_true, model_preds, class_names):
    fig, ax = plt.subplots(figsize=(10,10))
    for model_name, y_pred in model_preds.items():
        # Compute confusion matrix
        cm = confusion_matrix(y_true, y_pred)
        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # normalize the confusion matrix

        # Plot heat map
        sns.heatmap(cm_normalized, annot=True, fmt=".2f", linewidths=.5, square = True, cmap = 'Blues',
                    xticklabels=class_names, yticklabels=class_names);
        plt.ylabel('Actual label');
        plt.xlabel('Predicted label');
        all_sample_title = 'Confusion Matrix of {}'.format(model_name)  # Use the model name in the title
        plt.title(all_sample_title, size = 15);
        plt.show()

plot_multiclass_confusion_matrix(y_true, model_preds, class_names)

for model_name, y_pred in model_preds.items():
    # Get classification report in dictionary format
    report_dict = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)

    # Convert to DataFrame
    report_df = pd.DataFrame(report_dict).transpose()

    # Normalize a copy of 'support' column for the color representation
    support_normalized = (report_df['support'] - report_df['support'].min()) / (report_df['support'].max() - report_df['support'].min())
    support_normalized = 0.85 + (1-0.85)*support_normalized  # normalize between 0.85 and 1

    # Remove unnecessary rows
    report_df = report_df.drop(['accuracy', 'macro avg', 'weighted avg'])

    # Replace the 'support' column in the report_df with the normalized support
    report_df_normalized = report_df.copy()
    report_df_normalized['support'] = support_normalized

    # Generate heatmap
    plt.figure(figsize=(10,10))
    # Ensure the values for 'support' are represented as integers in the heatmap
    report_df['support'] = report_df['support'].astype(int)

    # Custom annotations to handle different formats for different columns
    annotations = report_df[['precision', 'recall', 'f1-score']].applymap('{:.2f}'.format).join(report_df[['support']].applymap('{:.0f}'.format)).values

    sns.heatmap(report_df_normalized[['precision', 'recall', 'f1-score', 'support']], annot=annotations, fmt='', cmap='mako', vmin=0.85, vmax=1)
    plt.title(f'Metrics Heatmap for {model_name}')

    plt.show()

"""# Generate wrong labels df"""

def get_incorrect_predictions(y_true, y_pred):
    # Find the indices where the predicted labels differ from the true labels
    incorrect_indices = np.where(y_true != y_pred)[0]
    return incorrect_indices

# Get the incorrect predictions for each model and store them in a dict
model_names = ['EfficientNetV2B2','DenseNet201','ViT']
incorrect_predictions_dict = {}
for i, y_pred in enumerate(y_preds):
    incorrect_predictions_dict[model_names[i]] = set(get_incorrect_predictions(y_true, y_pred))

# Get the intersection of all sets of incorrect predictions
common_incorrect_indices = set.intersection(*incorrect_predictions_dict.values())

# Create a DataFrame for the common incorrect predictions
common_incorrect_df = pd.DataFrame(columns=['model_name', 'correct_label', 'incorrect_prediction', 'image_path'])
for model_name in model_names:
    incorrect_image_paths = test_df.iloc[list(common_incorrect_indices)]['image_path'].values
    correct_labels = label_encoder.inverse_transform(y_true[list(common_incorrect_indices)])
    incorrect_predictions = label_encoder.inverse_transform(y_preds[model_names.index(model_name)][list(common_incorrect_indices)])
    temp_df = pd.DataFrame({
        'model_name': [model_name]*len(incorrect_image_paths),
        'correct_label': correct_labels,
        'incorrect_prediction': incorrect_predictions,
        'image_path': incorrect_image_paths
    })
    common_incorrect_df = pd.concat([common_incorrect_df, temp_df])

# Reset index of the DataFrame
common_incorrect_df.reset_index(drop=True, inplace=True)

common_incorrect_df

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# Extract the image paths
image_paths = common_incorrect_df['image_path'].values

# Set the number of rows and columns for the subplot
nrows = 4
ncols = 4

fig, axs = plt.subplots(nrows, ncols, figsize=(12, 12))

for i, ax in enumerate(axs.ravel()):
    if i < len(image_paths):
        img = mpimg.imread(image_paths[i])
        ax.imshow(img)
        ax.axis('off')
    else:
        ax.axis('off')

plt.tight_layout()
plt.show()

p = common_incorrect_df['image_path'][14]
plt.imshow(mpimg.imread(p))

show_images = [10,11,14]

"""### Compare between models"""

def get_pairwise_incorrect_predictions(model1, model2, third_model):
    # Get the intersection of incorrect predictions for model1 and model2
    incorrect_indices = incorrect_predictions_dict[model1].intersection(incorrect_predictions_dict[model2])

    # Find the indices where the third model made a correct prediction
    correct_third_model_indices = set(np.where(y_true == y_preds[model_names.index(third_model)])[0])

    # Remove these indices from the incorrect indices
    incorrect_indices = incorrect_indices - correct_third_model_indices

    # Create a DataFrame for the incorrect predictions
    incorrect_image_paths = test_df.iloc[list(incorrect_indices)]['image_path'].values
    correct_labels = label_encoder.inverse_transform(y_true[list(incorrect_indices)])
    incorrect_predictions1 = label_encoder.inverse_transform(y_preds[model_names.index(model1)][list(incorrect_indices)])
    incorrect_predictions2 = label_encoder.inverse_transform(y_preds[model_names.index(model2)][list(incorrect_indices)])
    incorrect_df = pd.DataFrame({
        'pair_name': [f"{model1}_{model2}"]*len(incorrect_image_paths),
        'third_model': [third_model]*len(incorrect_image_paths),
        'correct_label': correct_labels,
        'incorrect_prediction1': incorrect_predictions1,
        'incorrect_prediction2': incorrect_predictions2,
        'image_path': incorrect_image_paths
    })

    return incorrect_df

# Example usage:
incorrect_df = get_pairwise_incorrect_predictions('EfficientNetV2B2', 'DenseNet201', 'ViT')

incorrect_df

"""# ConvNet visualization"""

import tensorflow as tf
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.efficientnet import preprocess_input, decode_predictions
import numpy as np
import matplotlib.pyplot as plt
import cv2

# 获取原始EfficientNet模型
efficientnet = eff_model.get_layer('efficientnetv2-b2')
densenet = dense_model.get_layer('densenet201')

# 创建一个新的模型，只包含EfficientNet
grad_model = tf.keras.models.Model(
    [efficientnet.input], [efficientnet.get_layer('top_conv').output, efficientnet.output]
)
grad_model1 = tf.keras.models.Model(
    [densenet.input], [densenet.get_layer('conv5_block32_concat').output, densenet.output]
)

# 图像预处理函数
def preprocess_image(img_path):
    img = image.load_img(img_path, target_size=(224, 224))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)
    return img_array

# Grad-CAM函数
def make_gradcam_heatmap(img_array, model, last_conv_layer):
    with tf.GradientTape() as tape:
        last_conv_layer_output, preds = model(img_array)
        if preds.ndim == 2:
            preds = preds[:, 0]
        class_channel = preds

    grads = tape.gradient(class_channel, last_conv_layer_output)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    last_conv_layer_output = last_conv_layer_output[0]
    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    return heatmap.numpy()

def plot_grad_cam(df, model, grad_model, layer_name):
    for i in range(len(df)):
        img_path = df.image_path.iloc[i]

        # 图像预处理
        img_array = preprocess_image(img_path)

        # 使用grad_model和EfficientNet的最后一个卷积层生成热图
        heatmap = make_gradcam_heatmap(img_array, grad_model, model.get_layer(layer_name))

        # 使用opencv进行热图上色
        img = cv2.imread(img_path)
        heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))
        heatmap = np.uint8(255 * heatmap)
        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
        superimposed_img = heatmap * 0.4 + img
        cv2.imwrite(f'/content/grad_cam_result_{i}.jpg', superimposed_img)

        # 显示热图和原始图像
        img = cv2.imread(f'/content/grad_cam_result_{i}.jpg')
        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        plt.title(f"True label: {df.correct_label.iloc[i]}\nPredicted label: {df.incorrect_prediction.iloc[i]}")
        plt.axis('off')
        plt.show()

def plot_vit_attention(df, model):
    image_size = 224
    fig, axs = plt.subplots(1, len(df), figsize=(20, 20))

    for i in range(len(df)):
        img_path = df.image_path.iloc[i]
        true_label = df.correct_label.iloc[i]
        predicted_label = df.incorrect_prediction.iloc[i]

        # Get an image and compute the attention map
        image = utils.read(img_path, image_size)
        attention_map = visualize.attention_map(model=model, image=image)

        # Plot results
        axs[i].axis('off')
        axs[i].set_title(f"True label: {true_label}\nPredicted label: {predicted_label}")
        axs[i].imshow(attention_map)

    plt.show()

new_df = common_incorrect_df.iloc[[10,11,14]]

plot_grad_cam(new_df,efficientnet,grad_model,'top_conv')

plot_grad_cam(new_df,densenet,grad_model1,'conv5_block32_concat')

"""# Vit attention map"""

plot_vit_attention(new_df, vit_pretrained_model)

"""# True labels comparison"""

def get_correct_predictions_by_class(y_true, y_pred, class_indices):
    # Find the indices where the predicted labels are the same as the true labels
    correct_indices = np.where(y_true == y_pred)[0]
    # Keep only those indices that belong to the specified classes
    correct_indices = [idx for idx in correct_indices if y_true[idx] in class_indices]
    return correct_indices

# Specify the classes you're interested in
classes_of_interest = ['soft_plumaged_petrel', 'bermuda_petrel', 'black_winged_petrel']
# Get the corresponding encoded labels for these classes
class_indices_of_interest = label_encoder.transform(classes_of_interest)

# Get the correct predictions for each model and store them in a dict
model_names = ['EfficientNetV2B2','DenseNet201','ViT']
correct_predictions_dict = {}
for i, y_pred in enumerate(y_preds):
    correct_predictions_dict[model_names[i]] = set(get_correct_predictions_by_class(y_true, y_pred, class_indices_of_interest))

# Get the intersection of all sets of correct predictions
common_correct_indices = set.intersection(*correct_predictions_dict.values())

# Now we need to ensure that the selected indices contain images from all classes of interest
selected_indices = []
for class_index in class_indices_of_interest:
    # Find the indices of the correct predictions that belong to the current class
    class_indices = [idx for idx in common_correct_indices if y_true[idx] == class_index]
    # Randomly select one index from this list and add it to the selected indices
    selected_indices.append(random.choice(class_indices))

# Get the image paths of the selected indices
image_paths = test_df.iloc[selected_indices]['image_path'].values

new_image_df = dataset_df[dataset_df['image_path'].isin(image_paths)]
# suppose your dataframe is df
new_image_df = new_image_df.rename(columns={'label': 'correct_label','label_encoded':'incorrect_prediction'})

plot_grad_cam(new_image_df,efficientnet,grad_model,'top_conv')

plot_grad_cam(new_image_df,densenet,grad_model1,'conv5_block32_concat')

plot_vit_attention(new_image_df, vit_pretrained_model)

"""# below are the finidng image process"""

dataset_df.label.unique()

true_df = dataset_df[dataset_df['label']=='black_winged_petrel']

true_df.image_path.iloc[30]

from PIL import Image
# Open the image file
im = Image.open(true_df.image_path.iloc[30])

# Display the image
plt.imshow(im)
plt.show()

dataset_df

